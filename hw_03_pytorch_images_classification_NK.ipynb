{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bg8KCHOGTYAh"
   },
   "source": [
    "<center>\n",
    "<img src=\"http://newsless.ru/wp-content/uploads/2019/08/newsless.ru-top-posts-july-2019.jpg\" width=\"900\"> \n",
    "\n",
    "# Глубокое обучение и вообще: домашнее задание 3\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv4-mF0bTYAk"
   },
   "source": [
    "## О задании\n",
    "\n",
    "Это задание будет состоять из нескольких частей. Я пытался сделать их максимально независимыми друг от друга. Если вам не хочется делать какую-то из частей, смело её пропускайте.\n",
    "\n",
    "- __[1 балл]__ Подготовка данных. Нужно скачать данные и разложить их по папочкам. Всё надо делать кодом в python. \n",
    "- __[2 балла]__ Поставка данных. В этой части вам предстоит написать несколько итераторов для поставки данных.\n",
    "- __[3 балла]__ Напишите собственные архитектуры для обучения моделей.\n",
    "- __[1 балл]__ Пробуем визуализировать эмбеддинги картинок.\n",
    "- __[2 балла]__ Пробуем transfer learning и аугментацию.\n",
    "- __[1 балл]__ Пробуем файнтьюнинг\n",
    "\n",
    "Баллы даются за выполнение отдельных пунктов. Задачи в рамках одного раздела рекомендуется решать в том порядке, в котором они даны в задании. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQDDz5tZ-am4"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVmXtYf2_BFU"
   },
   "source": [
    "Обязательно пишите развернутые текстовые комментарии там, где это требуется. При их отсутствии будет сниматься от $50\\%$ баллов за задание.\n",
    "\n",
    "> Наверняка вам потребуется много гуглить о классификации и о том, как заставить её работать. Это нормально, все гуглят.\n",
    "\n",
    "Обязательно указывайте ссылки на чужой код, если вы его используете. Обязательно ссылайтесь на статьи / блогпосты / вопросы на stackoverflow / видосы от ютуберов-машинлернеров / курсы / подсказки от Дяди Васи и прочие дополнительные материалы, если вы их используете.\n",
    "\n",
    "Советуем использовать GPU. Если у вас его нет, используйте google colab. Если вам неудобно его использовать на постоянной основе, напишите и отладьте весь код локально на CPU, а затем запустите уже написанный ноутбук в колабе. Авторское решение задания достигает требуемой точности в колабе за 15 минут обучения.\n",
    "\n",
    "[FAQ по колабу](https://research.google.com/colaboratory/faq.html#idle-timeouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REx0JvxdTYAm"
   },
   "source": [
    "## Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов. За каждый день просрочки после мягкого дедлайна снимается 1 балл. После жёсткого дедлайна работы не принимаются. Даже при опозданиии на одну секунду. Сдавайте работы заранее. Мягкий дедлайн можно отодвинуть, воспользовавшись **late days policy** \n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Любой из студентов может быть вызван на защиту любого домашнего задания. В таком случае итоговая оценка студента определяется в результате защиты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4iovpTRTYAn"
   },
   "source": [
    "## Формат сдачи\n",
    "\n",
    "\n",
    "В форму необходимо загрузить ноутбук с выполенным заданием. Сам ноутбук называйте в формате hw-01-USERNAME.ipynb, где USERNAME — ваши фамилия и имя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2YnmEO8-nc_"
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-I2At4w4Gcn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dW8MDDu0-Xiy"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aydiNtHP2pUA"
   },
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Callable,\n",
    "    Iterable,\n",
    "    Generator,\n",
    "    Optional,\n",
    "    List,\n",
    "    Union\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Rrz1jRB4VwG"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ww7nABDj14cG"
   },
   "source": [
    "# 1. Подготовка данных (1 балл)\n",
    "\n",
    "> В этой части задания вам предстоит скачать данные и подготовить их к работе. Если вы не хотите это делать, сразу переходите к пункту 2 и воспользуйтесь уже скачанным вариантом. В таком случае, вы не получите балл за этот пункт. \n",
    "\n",
    "В этом задании вам предстоит научить нейросеть предсказывать жанр фильма по его постеру. Данные для этого скачайте с соотвествующего [соревнования на Kaggle,](https://www.kaggle.com/neha1703/movie-genre-from-its-poster) либо [с яндекс-диска,](https://disk.yandex.ru/d/PS_tBg-4Ttx6Lg) либо [c google-диска.](https://drive.google.com/file/d/1eeUdCQYlHEx97PgdkD70TQr4B1YEziH5/view?usp=sharing) Из этих данных нас будет интересовать csv-табличка со ссылками на все постеры. Для работы в колабе скачать данные поможет код, приведённый ниже. \n",
    "\n",
    "[Подробный гайд по утилите unzip](https://www.hostinger.ru/rukovodstva/unzip-linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EytBZ1xaq9Vl",
    "outputId": "20756e30-40be-46a8-9cfb-09618a18edbf"
   },
   "outputs": [],
   "source": [
    "# Скачиваем данные && разархивируем их && удаляем архив \n",
    "!gdown --id 1eeUdCQYlHEx97PgdkD70TQr4B1YEziH5 && unzip -q movie_posters.zip && rm movie_posters.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-2n6y2W3COT",
    "outputId": "9476ae44-4d0c-4237-b5ac-ab923cf556f4"
   },
   "outputs": [],
   "source": [
    "a = os.listdir(\"SampleMoviePosters/SampleMoviePosters\")\n",
    "len(a), a[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDjukxNJ3fqe"
   },
   "source": [
    "К сожалению, в датасете есть далеко не все представленные постеры. Зато в таблице `MovieGenre.csv` находится основная информация про фильмы, представленные в данных. В том числе есть ссылки на описание фильмов на Imdb и ссылки на их постеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "GqDjlk8E4ge6",
    "outputId": "a1a964b2-e6b5-4d28-f31c-fd8782552243"
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"MovieGenre.csv\", encoding=\"ISO-8859-1\")\n",
    "print(movies.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "Dlx0ZCAC6sH1",
    "outputId": "56d45447-8c4f-452a-8c1d-cb9b24be5fb4"
   },
   "outputs": [],
   "source": [
    "# Удаляем строки с пустыми id, жанром или постером\n",
    "movies.dropna(subset=['imdbId', 'Genre', 'Poster'], inplace=True)\n",
    "print(movies.shape)\n",
    "\n",
    "# удаляем строки-дубликаты\n",
    "movies.drop_duplicates(inplace=True)\n",
    "print(movies.shape)\n",
    "movies.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "ECX0Jus-XC-O",
    "outputId": "30e66040-e1e2-4d8c-89b3-defd3d596cbc"
   },
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijtNMO_bJoxt"
   },
   "source": [
    "__[0.4 балла]__ На первом этапе работы вам предстоит собрать все недостающие данные. \n",
    "\n",
    "Скачайте постеры к фильмам. Сохраните их в папку `images`. Каждому постеру, который вы качаете по ссылке из колонки `Poster` давайте имя вида `imdbId_жанры.jpg`.\n",
    "\n",
    "Ниже приведён пример того, как можно скачать один постер. Вам необходимо написать для этого цикл. Некоторые ссылки на постеры битые. В цикле придётся прописать `try-except`. Около 10% данных не скачается. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHAspgGmLcQx"
   },
   "outputs": [],
   "source": [
    "os.mkdir('images') # создали директорию для картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPOLhf4KLMqZ",
    "outputId": "1a9ecde0-3fb2-4afa-a65f-e210a465de80"
   },
   "outputs": [],
   "source": [
    "import urllib \n",
    "\n",
    "idd = movies.imdbId.values[2]\n",
    "url = movies.Poster.values[2]\n",
    "genre = movies.Genre.values[2]\n",
    "\n",
    "filename = 'images/' + str(idd) + '_' + genre + '.jpg'\n",
    "\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSiYCRSULXVQ",
    "outputId": "266fdfbd-5df8-4da3-85ae-df978372dc4c"
   },
   "outputs": [],
   "source": [
    "os.listdir('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhwNuMovkn9J"
   },
   "outputs": [],
   "source": [
    "files = os.listdir('images')  # получаем список файлов в папке images и удаляем их потом\n",
    "for file in files:\n",
    "    os.remove(os.path.join('images', file)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_Lcx1n5uVsb"
   },
   "outputs": [],
   "source": [
    "files_images = os.listdir('images') # себе для проверки, чтобы выделить id фильмов из постеров\n",
    "for file in files:\n",
    "  split_file = file.split('_')[0]\n",
    "  print(split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "hdwTpvbELvYs",
    "outputId": "07c064f5-2c72-475f-b612-ae517aef6530"
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "PIL.Image.open(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FM8qIdKMAii"
   },
   "source": [
    "Цикл для скачки может работать больше часа. Можно, но не обязательно, его распараллелить. Когда вы скачаете все данные, сделайте их бэкап на своём гугл-диске или на своём компьютере. Заархивировать папку вам поможет команда \n",
    "\n",
    "```\n",
    "!zip -r images.zip images\n",
    "```\n",
    "\n",
    "После архив надо скачать (он будет лежать в файловом хранилище колаба)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xtUHimnLvbL"
   },
   "outputs": [],
   "source": [
    "# цикл на скачивание изображений в нашу папочку\n",
    "for i in range(len(movies)):\n",
    "    try:\n",
    "        idd = movies.imdbId.values[i]\n",
    "        url = movies.Poster.values[i]\n",
    "        genre = movies.Genre.values[i]\n",
    "\n",
    "        filename = 'images/' + str(idd) + '_' + genre + '.jpg'\n",
    "\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "    except:\n",
    "        print(f\"Error downloading image for: {idd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTj45BhI4qXD"
   },
   "outputs": [],
   "source": [
    "# Как заархивировать и разархивировать:\n",
    "\n",
    "!zip -r images.zip images\n",
    "#  !unzip -q images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tAWVIIHzcdl",
    "outputId": "0bc608ef-fbef-44e2-a47e-479a56450835"
   },
   "outputs": [],
   "source": [
    "x = os.listdir('images')\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Piev6Tf0NLg5"
   },
   "source": [
    "__[0.1]__ выбросите из таблицы `MovieGenre.csv` все фильмы, которые не удалось скачать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYEKfVqRLvd2"
   },
   "outputs": [],
   "source": [
    "file_images = os.listdir('images')\n",
    "uniq_imd_posters = []\n",
    "for file in file_images:\n",
    "  split_file = file.split('_')[0]\n",
    "  uniq_imd_posters.append(int(split_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_sqIMaYy47p",
    "outputId": "82bacce3-ccee-414a-a8bc-a336d6d65479"
   },
   "outputs": [],
   "source": [
    "movies = movies[movies.imdbId.map(lambda x: x in uniq_imd_posters)]\n",
    "movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYaQ8XvlNOdL"
   },
   "source": [
    "Обратите внимание, что каждому фильму может соотвествовать несколько жанров. Они перечислены через разделитель `|`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0bxASPrLvgL",
    "outputId": "f9b1f88d-3619-49a4-aacb-4a0fe7589b87"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter([jtem for item in movies.Genre.values for jtem in item.split('|')])\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYDBDT_oNYVP"
   },
   "source": [
    "__[0.2]__ Давайте немного подчистим таргет.  \n",
    "\n",
    "- Удалите из данных все жанры, которые встречаются менее $100$ раз. От жанра Adult, к сожалению, придётся избавиться. Сохраните новые жанры в колонку `cleanGenre`.\n",
    "- Если у фильма после чистки не осталось жанров, удалите строчку с ним из таблицы с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "Ad-3wj7e47Tb",
    "outputId": "5bc57ccd-123a-45a3-b59b-2748ae30adee"
   },
   "outputs": [],
   "source": [
    "display(movies.head(3))\n",
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4H5W6rgkJbe5"
   },
   "outputs": [],
   "source": [
    "# функция для удаления жанров, которые встретились менее 100 раз и удаление пустых колонок с жанрами\n",
    "def process_genres(row):\n",
    "  genres = row['Genre'].split('|')\n",
    "  clean_genres = [genre for genre in genres if cnt[genre] >= 100]\n",
    "  return '|'.join(clean_genres)\n",
    "\n",
    "movies['cleanGenre'] = movies.apply(process_genres,axis = 1)\n",
    "movies = movies[movies.cleanGenre != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRCOv2g6NpE4"
   },
   "source": [
    "__[0.3]__ Разбейте выборку на train (80%) и validation (20%) случайным образом. Все файлы, которые будут в обучающей выборке, переложите в подпапку `images/train`. Все файлы, которые будут в валидационной выборке, переложите в подпапку `images/test`. Используйте для этого цикл и команду `os.rename(path, new_path)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rELnc1N83MXk"
   },
   "outputs": [],
   "source": [
    "# создаю директорию, и разделяю на выборки\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "\n",
    "with ZipFile('/content/images.zip', 'r') as zip_file:\n",
    "  zip_file.extractall('images')\n",
    "\n",
    "os.makedirs('images_clean/train', exist_ok=True)\n",
    "os.makedirs('images_clean/test', exist_ok=True)\n",
    "\n",
    "image_files = [f for f in os.listdir('images') if os.path.isfile(os.path.join('images', f))]\n",
    "\n",
    "random.shuffle(image_files)\n",
    "train_size = int(0.8 * len(image_files))\n",
    "train_files = image_files[:train_size]\n",
    "test_files = image_files[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XH0Col6ppt_P"
   },
   "outputs": [],
   "source": [
    "# далее идут 2 цикла, на перенос картинок в train и test\n",
    "for file in train_files:\n",
    "  old_path = os.path.join('images', file)\n",
    "  new_path = os.path.join('images_clean', 'train', file)\n",
    "  os.rename(old_path, new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeUKvuGfpwDU"
   },
   "outputs": [],
   "source": [
    "for file in test_files:\n",
    "  old_path = os.path.join('images', file)\n",
    "  new_path = os.path.join('images_clean', 'test', file)\n",
    "  os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osU78C2irmnG"
   },
   "outputs": [],
   "source": [
    "# в эту же папку гружу свой фрейм\n",
    "movies.to_csv('/content/images_clean/MovieGenre.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2Kqr5xaNbvS",
    "outputId": "5295d689-a119-4a69-fe84-fbffbdcdd5fc"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YglUQkyBOP8Y"
   },
   "source": [
    "Сделайте бэкап данных на свой гугл-диск. При решении дальнейших разделов используйте этот бэкап. Если вы решили, что не хотите решать часть, связанную с подготовкой данных, используйте мой бэкап. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSHa2KoAOyz2"
   },
   "source": [
    "# 2. Поставка данных (2 балла) \n",
    "\n",
    "Если вы выполнили первую часть работы и скачали свои данные, используйте во всех дальнейших пунктах именно их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SsTLvZXNiN9"
   },
   "outputs": [],
   "source": [
    "# Скачиваем данные && разархивируем их && удаляем архив \n",
    "# !gdown --id 1SDMBNpWW9gKEWR4tmGacHUvKfrQnoNRY && unzip -q images_clean.zip && rm images_clean.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaCtuF8mYfis"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "root_train = path + '/images_clean/train'\n",
    "root_val = path + '/images_clean/test'\n",
    "\n",
    "movies = pd.read_csv(path + \"/images_clean/MovieGenre.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# по id выдаёт название фильма\n",
    "imdbId2Title = dict(zip(movies.imdbId.values, movies.Title.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2wbdujyk8KI"
   },
   "outputs": [],
   "source": [
    "# Проверка все ли жанры из трэйна присутствуют в валидации\n",
    "\n",
    "uniq_train_genres = sorted(set([jtem for item in os.listdir(root_train) for jtem in item.split('_')[-1].split('.')[0].split(\"|\")]))\n",
    "uniq_val_genres = sorted(set([jtem for item in os.listdir(root_val) for jtem in item.split('_')[-1].split('.')[0].split(\"|\")]))\n",
    "\n",
    "# assert uniq_train_genres == uniq_val_genres\n",
    "\n",
    "UNIQ_GENRES = np.array(uniq_train_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWc_hKw7jf0M"
   },
   "source": [
    "Пользовался своими загруженными, код для загрузки и циклы написаны выше\n",
    "Можно выполнить твой код, но там использую только movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES1KaRCLPG21"
   },
   "source": [
    "\n",
    "> В этой части задания вам предстоит написать итераторы для дальнейшей работы с данными. Для этого нужно заполнить в функциях ниже все пропуски, а также дописать недостающие. Если вы не хотите писать итераторы, сразу переходите к обучению нейросетей. В таком случае вы не получите баллы за этот пункт. \n",
    "\n",
    "Для начала напишем несколько вспомогательных мелких функций. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZxXpKd_TYAz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_8nmLtEw61l"
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv(path + \"/images_clean/MovieGenre.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EA1xv5U8aQE"
   },
   "outputs": [],
   "source": [
    "# создаю колонку, с названием файла\n",
    "def create_poster_filename(row):\n",
    "    return f\"{row['imdbId']}_{row['cleanGenre']}.jpg\"\n",
    "\n",
    "movies['poster_filename'] = movies.apply(create_poster_filename, axis=1)\n",
    "poster_label_dict = dict(zip(movies['poster_filename'], movies['cleanGenre']))\n",
    "\n",
    "# уникальные жанры для фильмов\n",
    "all_image_files = os.listdir('images_clean/train') + os.listdir('images_clean/test')\n",
    "unique_genres = set()\n",
    "\n",
    "for file_name in all_image_files:\n",
    "    file_parts = file_name.split('_')\n",
    "    genres = file_parts[1].split('|')\n",
    "    genres[-1] = genres[-1].split('.')[0]\n",
    "    unique_genres.update(genres)\n",
    "unique_genres_dict = {genre: i for i, genre in enumerate(unique_genres)}\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_folder, unique_genres_dict, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.image_paths = [os.path.join(self.image_folder, f) for f in os.listdir(self.image_folder)]\n",
    "        self.image_labels = [self.parse_image_label(f) for f in os.listdir(self.image_folder)]\n",
    "        self.unique_genres_dict = unique_genres_dict\n",
    "        self.transform = transform\n",
    "\n",
    "    def parse_image_label(self, file_name):\n",
    "      file_parts = file_name.split('_')\n",
    "      image_id = int(file_parts[0])\n",
    "      genres = file_parts[1].split('|')\n",
    "      genres[-1] = genres[-1].split('.')[0]  # Удаляем расширение файла из последнего жанра\n",
    "      return image_id, genres\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        image_id, genres = self.image_labels[index]\n",
    "        label = torch.tensor([self.unique_genres_dict[g] for g in genres], dtype=torch.float32)\n",
    "        one_hot_label = torch.zeros(len(self.unique_genres_dict))\n",
    "        one_hot_label.scatter_(0, label.long(), 1)\n",
    "        return image, one_hot_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaPuIJ07TYAz"
   },
   "source": [
    "Объявите тестовый, валидационный и обучающий датасеты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eim5NJskrHlm"
   },
   "outputs": [],
   "source": [
    "# трансформер моих постеров\n",
    "data_transforms = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = CustomDataset('images_clean/train', unique_genres_dict=unique_genres_dict, transform=data_transforms)\n",
    "test_data = CustomDataset('images_clean/test', unique_genres_dict=unique_genres_dict, transform=data_transforms)\n",
    "\n",
    "#batch size\n",
    "batch_size = 32\n",
    "\n",
    "#DataLoader to train data \n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# DataLoader to test data \n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "train_size = int(0.8 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True,num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True,num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElShVZed14l7"
   },
   "source": [
    "# 3. Собственные архитектуры (3 балла). \n",
    "\n",
    "> В этой части задания вам предстоит написать и обучить две собственные нейросетевые архитектуры. Они должны отличаться друг от друга. Например, это могут быть RESNET и обычная свёрточная сетка. Ваш итоговый балл за это задание зависит от того, насколько качественно вы обучили модель и того, насколько аккуратно написан код. Постарайтесь воспользоваться расписанием на скорость обучения и ещё какими-нибудь эвристиками. \n",
    "\n",
    "Если вы написали в предыдущем пункте итераторы, используйте их. Если нет, подгрузите данные все картинки в память компьютера и работайте с ними. Чтобы картинки не забили всю оперативную память, можете сжать их. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmMkIAzEc_Zq"
   },
   "source": [
    "__[0.1 балл]__  Как будем применять нейросеть на новых данных? На какой таргет будем обучаться? \n",
    "\n",
    "__Ответ:__ На основе нашего датасета с постерами фильмов и метками жанров, мы можем построить нейронную сеть для мультиклассовой классификации, которая принимает изображение постера и предсказывает вероятности каждого жанра для данного постера. Таким образом, наша/моя будет обучаться на данных с множественными метками.\n",
    "\n",
    "Мне потребуется архитектура сверточной нейронной сети (CNN), например, предобученная на ImageNet, такая как ResNet, VGG или DenseNet.В качестве функции потерь я могу использовать Binary Cross Entropy Loss (BCELoss) или другую подходящую функцию потерь для многозначной классификации.\n",
    "\n",
    "Ваша цель обучения - предсказание жанров фильма на основе постера. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw3rl6tpcceb"
   },
   "source": [
    "__[0.9 балла]__ Для начала попробуем обучить несколько собственных нейронок. Собирите три принципиально различающиеся друг от друга архитектуры и обучите их. \n",
    "\n",
    "Архитектуры принципиально отличаются друг от друга, если в них закладываются разные идеи. Например, это могут быть полносвязная сеть, свёрточная сеть, ResNet, Inception, DenseNet и т.п. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ES7e70plbHyL"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# Изначальные параметры для след блоков\n",
    "step_size = 7\n",
    "gamma = 0.1\n",
    "# num_epochs = 50\n",
    "eta_min = 1e-5\n",
    "num_classes = len(unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8llKOhEIG8CH"
   },
   "outputs": [],
   "source": [
    "# Пишем обычную полносвязную нейронку\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "class FullyConnectedNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FullyConnectedNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.view(x.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# параметры для полносвязной модели\n",
    "input_size = 224 * 224 * 3\n",
    "hidden_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubL6nLK8H7F9"
   },
   "outputs": [],
   "source": [
    "# Пишем сверточную нейросеть\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(56 * 56 * 32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lP-2NcsoabVm",
    "outputId": "d5a89e6d-ac56-4e8e-f395-4c0ebdb1f701"
   },
   "outputs": [],
   "source": [
    "# Загруженная и уже обученная модель resnet 18\n",
    "from torchvision import models\n",
    "\n",
    "resnet_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the last layer to match the number of classes\n",
    "num_ftrs = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_ftrs, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTI2dhZimLZT"
   },
   "outputs": [],
   "source": [
    "# Блок для функций обучения модели и построения графика loss и accuracy\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=10):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_corrects = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_corrects += torch.sum(preds == labels.byte()).item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_corrects = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                preds = torch.sigmoid(outputs) > 0.5\n",
    "                val_loss += loss.item()\n",
    "                val_corrects += torch.sum(preds == labels.byte()).item()\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        train_accuracies.append(train_corrects / (len(train_loader.dataset) * num_classes))\n",
    "        val_accuracies.append(val_corrects / (len(val_loader.dataset) * num_classes))\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.4f}, Val Acc: {val_accuracies[-1]:.4f}')\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracies(train_accuracies, val_accuracies):\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbpFNu9xkkOU"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Qf8Fx10cInyu",
    "outputId": "44fc9822-9ea7-4f9d-819c-8d26a359f172"
   },
   "outputs": [],
   "source": [
    "# Полносвязная сетка\n",
    "fc_model = FullyConnectedNetwork(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(fc_model.parameters(), lr=0.01)\n",
    "fc_scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "# fc_scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=eta_min)\n",
    "\n",
    "# Train and evaluate\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_model(fc_model, train_loader, val_loader, criterion, optimizer,fc_scheduler ,device, num_epochs=10)\n",
    "plot_losses(train_losses, val_losses)\n",
    "plot_accuracies(train_accuracies, val_accuracies)\n",
    "\n",
    "# predictions_fc = predict(fc_model, test_loader, device)\n",
    "# print(\"Predictions for fc_model:\", predictions_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "78jgWs3hIn1c",
    "outputId": "9a9d13ee-b003-4750-97cb-67e49be45d68"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "conv_model = ConvNet(num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(conv_model.parameters(), lr=0.001)\n",
    "conv_scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "# conv_scheduler = CosineAnnealingLR(optimizer_conv, T_max=num_epochs, eta_min=eta_min)\n",
    "\n",
    "# Train and evaluate\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_model(conv_model, train_loader, val_loader, criterion, optimizer, conv_scheduler ,device, num_epochs=10)\n",
    "plot_losses(train_losses, val_losses)\n",
    "plot_accuracies(train_accuracies, val_accuracies)\n",
    "\n",
    "# predictions_conv = predict(conv_model, test_loader, device)\n",
    "# print(\"Predictions for fc_model:\", predictions_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "id": "ZFyWTxIxIn4D",
    "outputId": "c294b216-618e-4a0a-c6ea-798830c5a097"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.007)\n",
    "resnet_scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "# resnet_scheduler = CosineAnnealingLR(optimizer_conv, T_max=num_epochs, eta_min=eta_min)\n",
    "\n",
    "# Train and evaluate\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_model(resnet_model, train_loader, val_loader, criterion, optimizer, resnet_scheduler ,device, num_epochs=5)\n",
    "plot_losses(train_losses, val_losses)\n",
    "plot_accuracies(train_accuracies, val_accuracies)\n",
    "\n",
    "# predictions_resnet = predict(resnet_model, test_loader, device)\n",
    "# print(\"Predictions for fc_model:\", predictions_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMUMtEEV3ASe"
   },
   "source": [
    "__[2 балла]__ Теперь нам нужна модель, которая даст на тестовой выборке  __accuracy больше 50%.__ Если удастся, пробейте порог в __70%.__  Если не выйдет, просто поставьте несколько экспериментов.\n",
    "\n",
    "Можно использовать абсолютно всё, что вы знаете: любые активации, слои, сколь угодно большие свёрточные слои и глубокие сети. Единственное, нельзя использовать предобученные сети и дополнительные данные. \n",
    "\n",
    "__Главное правило: одно изменение на эксперимент.__   Если у вас есть 2 идеи по улучшению сети, сначала попробуйте их независимо. Может оказаться, что одно из них дало __+10%__ точности а другое __-7%__. А вы так и будете думать, что сделали 2 полезных изменения которые в сумме дают __+3%__. Если какая-то идея не работает — даже если она вам нравится - опишите ее и выкидывайте из дальнейших экспериментов. \n",
    "\n",
    "* __Дропаут.__ может помочь обучеть нейросетку в несколько раз глубже и избежать переобучения. Это круто, но не стоит сразу ставить дропаут в $0.5$. Слишком сильный дропаут приводет к недообучению (underfitting).  Более того, дропаут замедляет обучение. Если пытаетесь пробовать его, начинайте с не очень больших значений.\n",
    "\n",
    "* __Аугментация данных.__ На паре мы обсуждали, что если котов и собак чуток повращать и погнуть, они всё ещё останутся таковыми, а модель получит новую пищу для размышления. Для того, чтобы проделать трюк с аугментацией, придётся немного подрихтовать генератор данных. Для тестовой выборки не надо ничего аугментировать. Это нечестно. Обратите внимание, что если вы сами не в состоянии понять что за картинка перед вами, то и сеть тоже это не поймёт. \n",
    "\n",
    "* __Прекратитеть стакать слои!__ Есть более эффективные идеи. Реализуйте на Keras свой ResNet слой или свой Inception слой. Придётся написать немного кода в функциональном стиле, но я верю в вас.  Ещё можете попробовать Densely-connected convolutions и многие другие идеи. Для вдохновения [можете сходить сюда.](https://habr.com/ru/company/ods/blog/343822/)  Не надо только копировать огромные архитектуры под чистую, вам точно хватит более маленькой сетки. \n",
    "\n",
    "* __Долго != плохо__. Более глубокие архитектуры обычно требуют бОльше эпох до сходимости. Это значит, что в первые несколько эпох они могут быть хуже менее глубоких аналогов. Дайте им время, запаситесь чаем и обмажьтесь batch-norm-ом.\n",
    "\n",
    "* Обязательно попробуйте поставить расписание на learning rate. Уменьшайте его, когда лосс на валидации перестаёт убывать. В таком случае лучше учить модель с помощью цикла, а не метода `.fit`. \n",
    "\n",
    "* Вместо отрисовки картинок в тетрадке, можете логгировать свой [прогресс на wandb.](https://wandb.ai/quickstart) В этом случае приложите к тетрадке ссылку на дашборд с метриками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxA7lpYe3Ac-"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(64, 64, 2, 1)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, 2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        for stride in strides:\n",
    "            layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
    "            in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = nn.functional.adaptive_avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "id": "65biC5ufcbb4",
    "outputId": "74976959-1004-4556-a34b-4f2ca488ae9d"
   },
   "outputs": [],
   "source": [
    "my_resnet = MyResNet(num_classes).to(device)\n",
    "\n",
    "# оптимизатор\n",
    "optimizer_my_resnet = torch.optim.Adam(my_resnet.parameters(), lr=0.001)\n",
    "# scheduler\n",
    "scheduler_my_resnet = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_my_resnet, T_max=10)\n",
    "# функция потерь\n",
    "criterion_my_resnet = nn.CrossEntropyLoss()\n",
    "\n",
    "# Обучение модели\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_model(my_resnet, train_loader, val_loader, criterion_my_resnet, optimizer_my_resnet, scheduler_my_resnet ,device, num_epochs=5)\n",
    "plot_losses(train_losses, val_losses)\n",
    "plot_accuracies(train_accuracies, val_accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olRK5Tjs3I6m"
   },
   "source": [
    "Опишите свои <s>ощущения</s> результаты от проведенных экспериментов. Может быть несколько проще, если писать этот отчет сразу после каждого эксперимента.\n",
    "\n",
    "__Отчёт об экспериментах:__ \n",
    "Ну я решил сразу поставить dropout на 0.5 и посмотреть что будет происходить с сеткой.Решил сначала сделать эксперимент на 5 эпохах, но думаю, что потом сделаю поболее, чтобы дать сетке проявить себя во всей красе.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRolXitS3Tau"
   },
   "source": [
    "# 4. Эмбеддинги картинок (1 балл)\n",
    "\n",
    "__[0.2]__ Подгрузите из torchvision любую уже собранную за вас модель. Срежьте у неё последние слои, создав тем самым экстрактор фичей. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2m0aGIr78LK"
   },
   "outputs": [],
   "source": [
    "# ! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9WAZW9T4un5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn.manifold import TSNE\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A6zMb9-BLjz"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pY756puWEXAH"
   },
   "outputs": [],
   "source": [
    "# Загруз предобученную модель ResNet18\n",
    "model_resnet1 = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Удалиние последних слоев для создания экстрактора функций\n",
    "model_resnet1 = torch.nn.Sequential(*(list(model_resnet1.children())[:-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9qodzSyEdjR"
   },
   "source": [
    "__[0.2]__ Прогоните экстрактор через обучающую и тестовую выборки. Сохраните получившиеся эмбеддинги в отдельные матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7x5IFmUEXJd"
   },
   "outputs": [],
   "source": [
    "def extract_features(loader, model, device):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            features = model(images)\n",
    "            embeddings.extend(features.cpu().numpy().reshape(len(images), -1))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# эмбеддинги для обучающей и тестовой выборок\n",
    "train_embeddings = extract_features(train_loader, model_resnet1, device)\n",
    "test_embeddings = extract_features(test_loader, model_resnet1, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qzfut9CEEpmk"
   },
   "source": [
    "__[0.2]__ С помощью TSNE визуализируйте тестовую выборку. Раскрасьте точки в соотвествии с жанрами. Если у точки несколько жанров, выберите любой. Видно ли что-то интересное в полученной визуализации? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "xTGnzSIWEXQt",
    "outputId": "14fb0897-bd50-41e4-c329-9e147fd86fea"
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "test_embeddings_2d = tsne.fit_transform(test_embeddings)\n",
    "\n",
    "# Разделение меток на массив меток и применение кодировку\n",
    "labels = [label.tolist() for _, label in test_loader.dataset]\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform([label[0] for label in labels])\n",
    "\n",
    "# Визуализация\n",
    "plt.scatter(test_embeddings_2d[:, 0], test_embeddings_2d[:, 1], c=labels_encoded, cmap='tab10', s=5)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeTUo477DJz2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rvj_VT07E3BD"
   },
   "source": [
    "__[0.4]__ Подгрузите из `catboost` градиентный бустинг и обучите его классифицировать картинки. В качестве фичей используйте выделенные на прошлых шагах эмбеддинги. Каким оказыватся качество алгоритма на тестовой выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dk2wnj503U-U"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_embeddings, train_loader.dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создам и обучаем CatBoostClassifier\n",
    "catboost_clf = CatBoostClassifier(task_type='GPU', loss_function='MultiClass', verbose=False)\n",
    "catboost_clf.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "\n",
    "# Оцениваем качество на тестовой выборке\n",
    "test_accuracy = catboost_clf.score(test_embeddings, labels_encoded)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJVaRyJVH35E"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(test_embeddings, test_loader.dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создам и обучаем CatBoostClassifier\n",
    "catboost_clf = CatBoostClassifier(task_type='GPU', loss_function='MultiClass', verbose=False)\n",
    "catboost_clf.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "\n",
    "# Оцениваем качество на тестовой выборке\n",
    "test_accuracy = catboost_clf.score(test_embeddings, labels_encoded)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQRdzaXED8Pm"
   },
   "source": [
    "# 5. Transfer learning\n",
    "\n",
    "__[1 балл]__ Попробуем трансфер-лёрнинг!\n",
    "\n",
    "- Возьмите базовую сетку из предыдущего пунтка. Срежьте у неё последние сслои. Заморозьте в ней все параметры. \n",
    "- Добавьте поверх базовой части свою маленькую сетку.\n",
    "- Обучите добавленную часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YaEUWlnY3VIg"
   },
   "outputs": [],
   "source": [
    "# Создаем новую нейронную сеть на основе моей сети из пред пункта, котор называлась MyResNet\n",
    "class TransferMyResNet(MyResNet):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TransferMyResNet, self).__init__(num_classes)\n",
    "\n",
    "        # Удаление послед слоя \n",
    "        self.layers = list(self.children())[:-2]\n",
    "        self.feature_extractor = nn.Sequential(*self.layers)\n",
    "\n",
    "        # Замороз всех параметров сверточной части\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # создаю в дополнение свою маленькую сетку\n",
    "        self.new_part = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.new_part(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4gTwmOYF1f1"
   },
   "source": [
    "__[1 балл]__ Повторите то же самое упражнение, но теперь добавьте на этап обучения аугментацию данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3QinJGicF6LV"
   },
   "outputs": [],
   "source": [
    "augmented_transforms = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(20),\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomApply([transforms.ColorJitter(0.2, 0.2, 0.2, 0.1)], p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_data = CustomDataset('images_clean/train', unique_genres_dict=unique_genres_dict, transform=augmented_transforms)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Dataloader для траин данных\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fp6zjE3DG0tY"
   },
   "outputs": [],
   "source": [
    "transfer_my_resnet = TransferMyResNet(num_classes).to(device)\n",
    "\n",
    "# Функция потерь\n",
    "criterion_tms = nn.CrossEntropyLoss()\n",
    "\n",
    "# Оптимизатор\n",
    "optimizer_tms = optim.SGD(transfer_my_resnet.new_part.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Scheduler\n",
    "scheduler_tms = optim.lr_scheduler.ExponentialLR(optimizer_tms, gamma=0.95)\n",
    "\n",
    "\n",
    "# Обучаем модель\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_model(transfer_my_resnet, train_loader, val_loader, criterion_tms, optimizer_tms, scheduler_tms ,device, num_epochs=5)\n",
    "plot_losses(train_losses, val_losses)\n",
    "plot_accuracies(train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ9vh5Bi3Td_"
   },
   "source": [
    "# 6. Дообучение (fine-tuning)\n",
    "\n",
    "__[1]__ Попробуем сделать дообучение нейронной сети: \n",
    "\n",
    "- Возьмите базовую сетку из предыдущего пунтка. Срежьте у неё последние сслои. НЕ ЗАМОРАЖИВАЙТЕ её параметры. Они должны обучаться вместе со всей сетью. \n",
    "- Добавьте поверх базовой части свою маленькую сетку.\n",
    "- Обучите получившуюся архитектуру. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFAstOzOGD37"
   },
   "outputs": [],
   "source": [
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(CustomHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Создание модифицированной сети\n",
    "class ModifiedResNet(MyResNet):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedResNet, self).__init__(num_classes)\n",
    "        self.custom_head = CustomHead(256, 128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = super(ModifiedResNet, self).forward(x)\n",
    "        x = self.custom_head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdBOOenOu3ua"
   },
   "outputs": [],
   "source": [
    "class SmallNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "small_net = SmallNet(num_classes).to(device)\n",
    "\n",
    "# Удал последний полносвязный слой из MyResNet\n",
    "base_net = nn.Sequential(*list(my_resnet.children())[:-1])\n",
    "\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self, base_net, small_net):\n",
    "        super(NewModel, self).__init__()\n",
    "        self.base_net = base_net\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.small_net = small_net\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_net(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.small_net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Удаление последний полносвязный слой из MyResNet\n",
    "base_net = nn.Sequential(*list(my_resnet.children())[:-1])\n",
    "\n",
    "# новуя модель с базовой частью MyResNet и маленькой сеткой\n",
    "new_model = NewModel(base_net, small_net).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9n_T4fxlJZK7"
   },
   "outputs": [],
   "source": [
    "new_model = NewModel(base_net, small_net).to(device)\n",
    "\n",
    "criterion_new_mod = nn.CrossEntropyLoss()\n",
    "optimizer_new_mod  = optim.SGD(new_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler_new_mod  = optim.lr_scheduler.StepLR(optimizer_new_mod, step_size=7, gamma=0.1)\n",
    "\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_model(new_model, train_loader, val_loader, criterion_new_mod, optimizer_new_mod, scheduler_new_mod ,device, num_epochs=5)\n",
    "plot_losses(train_losses, val_losses)\n",
    "plot_accuracies(train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNqaSG31FS9O"
   },
   "source": [
    "Подведём итоги. Какая из моделей показала самое хорошее качество? Какая оказалась самой плохой? Какие из архитектур получилось побить с помощью градиентного бустинга?\n",
    "\n",
    "__Ответ:__ ..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
